name: AQUA tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1" # run every Monday night at 3AM UTC

permissions:
  contents: read

defaults:
  run:
    # NOTE: We must take care with the shell value here. We have steps
    #       with mutiline YAML strings. 
    #       These get converted into shell scripts.
    #       If execute as ``bash -l fail_first_command.sh``
    #       then it would fail the first command but run the second
    #       command. The default value in GitHub is ``--noprofile --norc -eo pipefail``.
    #       https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsshell
    #       We removed the noprofile and norc so we have pytest set by Conda in our PATH.
    # NOTE2: login should be kept becuse the action micromamba/setup-micromamba
    #        writes the environment activation script in the .bashrc file.
    shell: bash -l -eo pipefail {0}
jobs:
  aqua_test:
    # NOTE: this option can be uncommented to run the job only when
    #       a pull request contains a label with the name "Run Tests" or "Ready to Merge".
    if: contains(github.event.pull_request.labels.*.name, 'run tests') || contains(github.event.pull_request.labels.*.name, 'ready to merge')
    env:
      # You can disable coverage by changing this to false. You can
      # also add other Python versions to the matrix, pinning the
      # coverage job to be executed only on certain versions.
      COVERAGE_ENABLED: ${{ matrix.python-version == '3.12' }}
      DEBIAN_FRONTEND: noninteractive
      GRID_DEFINITION_PATH: /tmp
      # This is needed for the FDB tests.
      FDB5_CONFIG_FILE: /app/etc/fdb/config.yaml

      # This is needed to avoid FDB errors with ClimateDT specific keys.
      # METKIT_RAW_PARAM: 1
    runs-on: ubuntu-latest
    # This option applies to the individual job of a matrix.
    continue-on-error: false
    container:
      # To run FDB tests we need to use a Docker image with FDB installed.
      image: ghcr.io/destine-climate-dt/ubuntu24.04-fdb5.14-eccodes2.39.2-aqua:docker24.04_updated
      credentials:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
      options: --user root
    permissions:
      contents: read
      issues: write
      pull-requests: write
    strategy:
      # This option applies to all jobs in the matrix.
      # If true, the entire matrix will stop running when one of the jobs fails.
      fail-fast: false
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          path: AQUA
      # The FDB docker image does not have git and other dependencies
      - name: Install GH Actions dependencies
        run: |
          # Ubuntu dependencies (Git, curl, ...)
          apt-get update && \
            apt-get install -y \
              cargo \
              curl \
              git \
              rustc
      - name: Checkout Climate-DT-catalog repository
        uses: actions/checkout@v4
        with:
          repository: DestinE-Climate-DT/Climate-DT-catalog
          token: github_pat_${{ secrets.CLIMATEDT_TOKEN }}
          path: Climate-DT-catalog 
      - name: Clone GitLab data-portfolio repository
        run: |
          git clone https://oauth2:${{ secrets.BSC_GITLAB }}@earth.bsc.es/gitlab/digital-twins/de_340-2/data-portfolio data-portfolio
      - name: List Workspace Contents
        run: |
          echo "Current Directory: $PWD"
          ls -l
      # Using GH Action https://github.com/marketplace/actions/cargo-install
      # as it caches the binary installation (the official cargo is tailored for
      # building Rust applications, this one is for installing tools with Cargo).
      - name: Install htmlq
        if: ${{ env.COVERAGE_ENABLED }}
        uses: baptiste0928/cargo-install@v3.1.1
        with:
          crate: htmlq
          cache-key: cargo-coverage
      - name: Set up Micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          micromamba-version: 'latest'
          environment-file: AQUA/environment.yml 
          environment-name: aqua
          cache-downloads: true
          cache-environment: false
          condarc: |
            channels:
              - conda-forge
          create-args: >-
            python=${{ matrix.python-version }}
      - name: List Pip packages
        run: |
          pip freeze
      - name: Install Flake8
        run: |
          python -m pip install flake8
      - name: Lint with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics --exclude=__init__.py
      - name: Download and set up tests
        run: |
          cd AQUA
          ./download_data_for_tests.sh
          ./tests/teleconnections/download_data_for_tests.sh
      - name: Set up FDB
        run: |
          export
          # FDB for GSV
          rm -rf /app/
          ls -l *
          cp -r ./AQUA/AQUA_tests/fdb/ /app/
          cat /app/etc/fdb/config.yaml
          mkdir -pv /app/localroot/
          cd /app/
          fdb-write sample_test_data.grib
          fdb-write sample_test_data_d1.grib
          ls -l /app/localroot
          # The fdb-list command is a good smoke test.
          fdb-list class=ea,expver=0001
          # But the fdb-read using a request is more like what pyfdb does.
          # When it fails, the test.grib file will have 0 (zero) messages.
          fdb-read sample_test_data_fdb_request test.grib
          grib_dump test.grib
      - name: Set up AQUA
        run: |
          # Initialize the AQUA catalog in the $HOME/.aqua folder
          aqua -vv install github
          # Add the ci/cd catalog
          aqua -vv add ci
          # Double check the catalogs
          aqua -vv list
      - name: Run tests
        # NOTE: We could gain a few seconds in the build, if needed,
        #       by running with coverage in only one matrix job run.
        # NOTE2: following issue #436 we are running the tests with the default
        #        shell and not with the micromamba shell.
        run: |
          # Produce the HTML report. Defaults to writing in htmlcov/index.html.
          cd AQUA
          pytest --cov=aqua --cov-report=html --cov-report=xml --cov-branch -m "aqua or slow or gsv or graphics or catgen or timeseries or ecmean or seaice or teleconnections"
      - name: Processing coverage
        run: |
          if [[ ${COVERAGE_ENABLED} ]]; then
            cd AQUA
            # Extract the top header of the pytest HTML report.
            # Passes the HTML through htmlq, extracting the first H1 displayed.
            # Uses tr to delete breaklines and squeeze-repeats blank spaces,
            # saving space - this is used for an HTTP REST request to GitHub API.
            COV_HEADER=$(cat htmlcov/index.html | htmlq --pretty 'header > div > h1:first-of-type' | tr -d '\n' | tr -s ' ')
            
            # Extract the table of the pytest HTML report.
            # Passes the HTML through htmlq, extracting the table element.
            # Uses tr to delete breaklines and squeeze-repeats blank spaces.
            # Then calls sed with an expression that replaces the HTML a
            # elements by only its text.
            COV_TABLE=$(cat htmlcov/index.html | htmlq --pretty 'table' | tr -d '\n' | tr -s ' ' | sed 's|<a[^>]*>\([^<]*\)</a>|\1|g')

            # Produce an simplified HTML report.
            echo "${COV_HEADER}${COV_TABLE}" > coverage.html

            # Now simply use pandoc to convert HTML to Markdown.
            pandoc --from html --to 'markdown_strict+pipe_tables' coverage.html -o coverage.md

            # Append the missing lines, using pycobertura (which was used previously,
            # but replaced by pandoc/htmlq due to missing branch coverage info
            # https://github.com/aconrad/pycobertura/issues/167
            pycobertura show coverage.xml --format markdown --source aqua | awk -F"|" '{print "|" $2 "|" $6 "|"}' > missing.md
          
            echo -en '\n\n## Missing Lines\n\n' >> coverage.md

            cat missing.md >> coverage.md
          fi
      - name: Publish coverage reports (stdout)
        # Publish the coverage reports in only one matrix job run.
        # Only run if **NOT** running in a pull request (see step below).
        if: ${{ github.event_name != 'pull_request' && env.COVERAGE_ENABLED }}
        run: |
          cat AQUA/coverage.md
      - name: Publish coverage reports (bot)
        # Publish the coverage reports in only one matrix job run.
        # Only run if running in a pull request.
        # See for more: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#example-using-contexts
        if: ${{ github.event_name == 'pull_request' && env.COVERAGE_ENABLED }}
        # Comment on an issue or pull request using GH Actions tooling:
        # https://github.com/actions/github-script#comment-on-an-issue
        uses: actions/github-script@v7
        id: coverage-report
        with:
          github-token: ${{secrets.GITHUB_TOKEN}}
          # Based on: https://github.com/actions/github-script/blob/060d68304cc19ea84d828af10e34b9c6ca7bdb31/.github/workflows/pull-request-test.yml
          script: |
            // Get the existing comments.
            const {data: comments} = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.number,
            })

            // Find any comment already made by the bot.
            const botComment = comments.find(comment => comment.user.id === 41898282)
            const fs = require("fs").promises
            let commentBody = await fs.readFile("AQUA/coverage.md", "utf8")
            // Replace _ by \_ since it is Markdown. Pandoc already adds it,
            // but pycobertura does not adds it. Thus the negative lookahead
            // ignoring already escaped underscores.
            commentBody = `${commentBody}`.replace(/_(?<!\\_)/g, '\\_')

            if (botComment) {
              console.log(`Updating comment in ${context.repo.owner}/${context.repo.repo}, comment ID: ${botComment.id}`)
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              })
            } else {
              console.log(`Creating comment in ${context.repo.owner}/${context.repo.repo}`)
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              })
            }
