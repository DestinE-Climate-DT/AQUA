{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TCs_class_methods import TCs\n",
    "from aqua.util import load_yaml\n",
    "import numpy as np\n",
    "from aqua.logger import log_configure\n",
    "mainlogger = log_configure('INFO', log_name='MAIN')\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming of chunks of data implemented on DetectNodes, then run StitchNodes every period of n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 13:16:34 :: TCs :: WARNING  -> Initialised streaming for 5 days starting on 2020-08-01\n",
      "2023-04-21 13:16:57 :: TCs :: WARNING  -> processing time step 20200801T00\n",
      "2023-04-21 13:17:11 :: TCs :: WARNING  -> processing time step 20200801T06\n",
      "2023-04-21 13:17:22 :: TCs :: WARNING  -> processing time step 20200801T12\n",
      "2023-04-21 13:17:34 :: TCs :: WARNING  -> processing time step 20200801T18\n",
      "2023-04-21 13:17:45 :: TCs :: WARNING  -> processing time step 20200802T00\n",
      "2023-04-21 13:18:05 :: TCs :: WARNING  -> processing time step 20200802T06\n",
      "2023-04-21 13:18:17 :: TCs :: WARNING  -> processing time step 20200802T12\n",
      "2023-04-21 13:18:29 :: TCs :: WARNING  -> processing time step 20200802T18\n",
      "2023-04-21 13:18:44 :: TCs :: WARNING  -> processing time step 20200803T00\n",
      "2023-04-21 13:18:56 :: TCs :: WARNING  -> processing time step 20200803T06\n",
      "2023-04-21 13:19:08 :: TCs :: WARNING  -> processing time step 20200803T12\n",
      "2023-04-21 13:19:20 :: TCs :: WARNING  -> processing time step 20200803T18\n",
      "2023-04-21 13:19:32 :: TCs :: WARNING  -> processing time step 20200804T00\n",
      "2023-04-21 13:19:44 :: TCs :: WARNING  -> processing time step 20200804T06\n",
      "2023-04-21 13:19:55 :: TCs :: WARNING  -> processing time step 20200804T12\n",
      "2023-04-21 13:20:07 :: TCs :: WARNING  -> processing time step 20200804T18\n",
      "2023-04-21 13:20:18 :: TCs :: WARNING  -> processing time step 20200805T00\n",
      "2023-04-21 13:20:30 :: TCs :: WARNING  -> processing time step 20200805T06\n",
      "2023-04-21 13:20:41 :: TCs :: WARNING  -> processing time step 20200805T12\n",
      "2023-04-21 13:20:52 :: TCs :: WARNING  -> processing time step 20200805T18\n",
      "2023-04-21 13:21:11 :: MAIN :: WARNING  -> New streaming from 20200806T00 to 20200810T23\n",
      "2023-04-21 13:21:11 :: TCs :: WARNING  -> processing time step 20200806T00\n",
      "2023-04-21 13:21:23 :: TCs :: WARNING  -> processing time step 20200806T06\n",
      "2023-04-21 13:21:34 :: TCs :: WARNING  -> processing time step 20200806T12\n",
      "2023-04-21 13:21:46 :: TCs :: WARNING  -> processing time step 20200806T18\n",
      "2023-04-21 13:21:58 :: TCs :: WARNING  -> processing time step 20200807T00\n",
      "2023-04-21 13:22:10 :: TCs :: WARNING  -> processing time step 20200807T06\n",
      "2023-04-21 13:22:22 :: TCs :: WARNING  -> processing time step 20200807T12\n",
      "2023-04-21 13:22:33 :: TCs :: WARNING  -> processing time step 20200807T18\n",
      "2023-04-21 13:22:47 :: TCs :: WARNING  -> processing time step 20200808T00\n",
      "2023-04-21 13:22:59 :: TCs :: WARNING  -> processing time step 20200808T06\n",
      "2023-04-21 13:23:10 :: TCs :: WARNING  -> processing time step 20200808T12\n",
      "2023-04-21 13:23:24 :: TCs :: WARNING  -> processing time step 20200808T18\n",
      "2023-04-21 13:23:37 :: TCs :: WARNING  -> processing time step 20200809T00\n",
      "2023-04-21 13:23:50 :: TCs :: WARNING  -> processing time step 20200809T06\n",
      "2023-04-21 13:24:02 :: TCs :: WARNING  -> processing time step 20200809T12\n",
      "2023-04-21 13:24:13 :: TCs :: WARNING  -> processing time step 20200809T18\n",
      "2023-04-21 13:24:25 :: TCs :: WARNING  -> processing time step 20200810T00\n",
      "2023-04-21 13:24:36 :: TCs :: WARNING  -> processing time step 20200810T06\n",
      "2023-04-21 13:24:48 :: TCs :: WARNING  -> processing time step 20200810T12\n",
      "2023-04-21 13:25:00 :: TCs :: WARNING  -> processing time step 20200810T18\n",
      "2023-04-21 13:25:17 :: MAIN :: WARNING  -> Running stitch nodes from 2020-08-01 00:00:00 to 2020-08-06 00:00:00\n",
      "2023-04-21 13:25:18 :: TCs :: WARNING  -> running stitch nodes from 20200801-20200805\n",
      "2023-04-21 13:25:22 :: TCs :: WARNING  -> storing stitched tracks for msl\n",
      "2023-04-21 13:25:23 :: TCs :: WARNING  -> storing stitched tracks for 10u\n",
      "2023-04-21 13:25:23 :: TCs :: WARNING  -> storing stitched tracks for 10v\n",
      "2023-04-21 13:25:24 :: TCs :: WARNING  -> storing stitched tracks for tp\n",
      "2023-04-21 13:25:27 :: MAIN :: WARNING  -> New streaming from 20200811T00 to 20200815T23\n",
      "2023-04-21 13:25:27 :: TCs :: WARNING  -> processing time step 20200811T00\n",
      "2023-04-21 13:25:41 :: TCs :: WARNING  -> processing time step 20200811T06\n",
      "2023-04-21 13:26:09 :: TCs :: WARNING  -> processing time step 20200811T12\n",
      "2023-04-21 13:26:23 :: TCs :: WARNING  -> processing time step 20200811T18\n",
      "2023-04-21 13:26:36 :: TCs :: WARNING  -> processing time step 20200812T00\n",
      "2023-04-21 13:26:49 :: TCs :: WARNING  -> processing time step 20200812T06\n",
      "2023-04-21 13:27:03 :: TCs :: WARNING  -> processing time step 20200812T12\n",
      "2023-04-21 13:27:23 :: TCs :: WARNING  -> processing time step 20200812T18\n",
      "2023-04-21 13:27:37 :: TCs :: WARNING  -> processing time step 20200813T00\n",
      "2023-04-21 13:27:50 :: TCs :: WARNING  -> processing time step 20200813T06\n",
      "2023-04-21 13:28:16 :: TCs :: WARNING  -> processing time step 20200813T12\n",
      "2023-04-21 13:28:30 :: TCs :: WARNING  -> processing time step 20200813T18\n",
      "2023-04-21 13:28:44 :: TCs :: WARNING  -> processing time step 20200814T00\n",
      "2023-04-21 13:29:45 :: TCs :: WARNING  -> processing time step 20200814T06\n",
      "2023-04-21 13:30:20 :: TCs :: WARNING  -> processing time step 20200814T12\n",
      "2023-04-21 13:30:35 :: TCs :: WARNING  -> processing time step 20200814T18\n",
      "2023-04-21 13:30:48 :: TCs :: WARNING  -> processing time step 20200815T00\n",
      "2023-04-21 13:31:00 :: TCs :: WARNING  -> processing time step 20200815T06\n",
      "2023-04-21 13:31:20 :: TCs :: WARNING  -> processing time step 20200815T12\n",
      "2023-04-21 13:31:37 :: TCs :: WARNING  -> processing time step 20200815T18\n",
      "2023-04-21 13:32:29 :: MAIN :: WARNING  -> Running stitch nodes from 2020-08-06 00:00:00 to 2020-08-11 00:00:00\n",
      "2023-04-21 13:32:30 :: TCs :: WARNING  -> running stitch nodes from 20200806-20200810\n",
      "2023-04-21 13:32:31 :: TCs :: WARNING  -> storing stitched tracks for msl\n",
      "2023-04-21 13:32:39 :: TCs :: WARNING  -> storing stitched tracks for 10u\n",
      "2023-04-21 13:32:40 :: TCs :: WARNING  -> storing stitched tracks for 10v\n",
      "2023-04-21 13:32:41 :: TCs :: WARNING  -> storing stitched tracks for tp\n",
      "2023-04-21 13:32:45 :: MAIN :: WARNING  -> New streaming from 20200816T00 to 20200820T23\n",
      "2023-04-21 13:32:45 :: TCs :: WARNING  -> processing time step 20200816T00\n",
      "2023-04-21 13:32:59 :: TCs :: WARNING  -> processing time step 20200816T06\n",
      "2023-04-21 13:33:29 :: TCs :: WARNING  -> processing time step 20200816T12\n",
      "2023-04-21 13:33:43 :: TCs :: WARNING  -> processing time step 20200816T18\n",
      "2023-04-21 13:33:56 :: TCs :: WARNING  -> processing time step 20200817T00\n",
      "2023-04-21 13:34:09 :: TCs :: WARNING  -> processing time step 20200817T06\n",
      "2023-04-21 13:34:28 :: TCs :: WARNING  -> processing time step 20200817T12\n",
      "2023-04-21 13:35:04 :: TCs :: WARNING  -> processing time step 20200817T18\n",
      "2023-04-21 13:35:17 :: TCs :: WARNING  -> processing time step 20200818T00\n",
      "2023-04-21 13:36:05 :: TCs :: WARNING  -> processing time step 20200818T06\n",
      "2023-04-21 13:36:47 :: TCs :: WARNING  -> processing time step 20200818T12\n",
      "2023-04-21 13:37:24 :: TCs :: WARNING  -> processing time step 20200818T18\n",
      "2023-04-21 13:37:37 :: TCs :: WARNING  -> processing time step 20200819T00\n",
      "2023-04-21 13:38:06 :: TCs :: WARNING  -> processing time step 20200819T06\n",
      "2023-04-21 13:38:39 :: TCs :: WARNING  -> processing time step 20200819T12\n",
      "2023-04-21 13:38:55 :: TCs :: WARNING  -> processing time step 20200819T18\n",
      "2023-04-21 13:39:34 :: TCs :: WARNING  -> processing time step 20200820T00\n",
      "2023-04-21 13:39:49 :: TCs :: WARNING  -> processing time step 20200820T06\n"
     ]
    }
   ],
   "source": [
    "# load the config file\n",
    "tdict = load_yaml('config/config_levante.yml')\n",
    "\n",
    "# initialise tropical class with streaming options\n",
    "tropical = TCs(tdict=tdict, streaming=True, stream_step=tdict['stream']['streamstep'], stream_unit=\"days\", \n",
    "               stream_startdate=tdict['time']['startdate'], loglevel = \"WARNING\")\n",
    "\n",
    "# retrieve the data and call detect nodes on the first chunk of data\n",
    "tropical.data_retrieve()\n",
    "tropical.detect_nodes_zoomin()\n",
    "\n",
    "# parameters for stitch nodes (to save tracks of selected variables in netcdf)\n",
    "n_days_stitch = tdict['stitch']['n_days_freq'] + tdict['stitch']['n_days_ext']\n",
    "last_run_stitch = pd.Timestamp(tropical.startdate)\n",
    "\n",
    "# loop to simulate streaming\n",
    "while len(np.unique(tropical.data2d.time.dt.day)) == tdict['stream']['streamstep']:\n",
    "    tropical.data_retrieve()\n",
    "    mainlogger.warning(f\"New streaming from {pd.Timestamp(tropical.stream_startdate).strftime('%Y%m%dT%H')} to {pd.Timestamp(tropical.stream_enddate).strftime('%Y%m%dT%H')}\")\n",
    "    timecheck = (tropical.data2d.time.values > np.datetime64(tdict['time']['enddate']))\n",
    "    \n",
    "    if timecheck.any():\n",
    "        tropical.stream_enddate = tropical.data2d.time.values[np.where(timecheck)[0][0]-1] \n",
    "        mainlogger.warning(f'Modifying the last stream date {tropical.stream_enddate}') \n",
    "\n",
    "    tropical.detect_nodes_zoomin()\n",
    "\n",
    "    if timecheck.any():\n",
    "        break\n",
    "    \n",
    "    # add one hour since time ends at 23\n",
    "    dayspassed = (tropical.stream_enddate + np.timedelta64(1, 'h')- last_run_stitch) / np.timedelta64(1, 'D')\n",
    "\n",
    "    if (dayspassed >= n_days_stitch):\n",
    "        end_run_stitch = last_run_stitch + np.timedelta64(tdict['stitch']['n_days_freq'], 'D')\n",
    "        mainlogger.warning(f'Running stitch nodes from {last_run_stitch} to {end_run_stitch}')\n",
    "        tropical.stitch_nodes_zoomin(startdate=last_run_stitch, enddate=end_run_stitch,\n",
    "            n_days_freq=tdict['stitch']['n_days_freq'], n_days_ext=tdict['stitch']['n_days_ext'])\n",
    "        last_run_stitch = copy.deepcopy(end_run_stitch)\n",
    "# problem: bring the time handling to pandas to avoid mismatch with dates\n",
    "end_run_stitch = np.datetime64(tdict['time']['enddate'])\n",
    "mainlogger.warning(f'Running stitch nodes from {last_run_stitch} to {end_run_stitch}')\n",
    "tropical.stitch_nodes_zoomin(startdate=pd.Timestamp(last_run_stitch), enddate=pd.Timestamp(end_run_stitch),\n",
    "            n_days_freq=tdict['stitch']['n_days_freq'], n_days_ext=tdict['stitch']['n_days_ext'])\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version without loop on the streaming (streaming is implemented but only to retrieve chunks of data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration file with all the tempest options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdict = load_yaml('config/config_levante.yml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the class with the dictionary from the YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:05:33 :: TCs :: WARNING  -> Initialised streaming for 2 days starting on 2020-08-01\n"
     ]
    }
   ],
   "source": [
    "tropical = TCs(tdict=tdict, streaming=True, stream_step=tdict['stream']['streamstep'], stream_unit=\"days\", \n",
    "               stream_startdate=tdict['time']['startdate'], loglevel = \"WARNING\")\n",
    "tropical.data_retrieve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code on a loop on the detect nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 11:54:37 :: TCs :: WARNING  -> processing time step 20200804T00\n",
      "2023-04-18 11:54:48 :: TCs :: WARNING  -> processing time step 20200804T06\n",
      "2023-04-18 11:54:58 :: TCs :: WARNING  -> processing time step 20200804T12\n",
      "2023-04-18 11:55:08 :: TCs :: WARNING  -> processing time step 20200804T18\n",
      "2023-04-18 11:55:20 :: TCs :: WARNING  -> processing time step 20200805T00\n",
      "2023-04-18 11:55:32 :: TCs :: WARNING  -> processing time step 20200805T06\n",
      "2023-04-18 11:55:43 :: TCs :: WARNING  -> processing time step 20200805T12\n",
      "2023-04-18 11:55:55 :: TCs :: WARNING  -> processing time step 20200805T18\n",
      "2023-04-18 11:56:06 :: TCs :: WARNING  -> processing time step 20200806T00\n",
      "2023-04-18 11:56:18 :: TCs :: WARNING  -> processing time step 20200806T06\n",
      "2023-04-18 11:56:30 :: TCs :: WARNING  -> processing time step 20200806T12\n",
      "2023-04-18 11:56:43 :: TCs :: WARNING  -> processing time step 20200806T18\n"
     ]
    }
   ],
   "source": [
    "tropical.detect_nodes_zoomin()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code for the detect nodes, after having set up the days freq and the extensions days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 13:57:15 :: TCs :: WARNING  -> running stitch nodes from 2020-08-01 to 2020-09-30\n",
      "2023-04-13 13:57:19 :: TCs :: WARNING  -> storing stitched tracks for msl\n",
      "2023-04-13 14:30:48 :: TCs :: WARNING  -> storing stitched tracks for 10u\n",
      "2023-04-13 14:46:32 :: TCs :: WARNING  -> storing stitched tracks for 10v\n",
      "2023-04-13 15:00:24 :: TCs :: WARNING  -> storing stitched tracks for tp\n",
      "2023-04-13 15:15:47 :: TCs :: WARNING  -> running stitch nodes from 2020-08-01 to 2020-09-30\n",
      "2023-04-13 15:15:55 :: TCs :: WARNING  -> storing stitched tracks for msl\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tropical.stitch_nodes_zoomin(start_date=tdict['time']['start_date'], end_date=tdict['time']['end_date'],\n",
    "                             n_days_freq=tdict['stitch']['n_days_freq'], n_days_ext=tdict['stitch']['n_days_ext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# variables to be plotted\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m tdict[\u001b[39m'\u001b[39m\u001b[39mvarlist\u001b[39m\u001b[39m'\u001b[39m]: \n\u001b[1;32m      5\u001b[0m     tracks_nc_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tdict[\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mfulldir\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtempest_tracks_\u001b[39m\u001b[39m{\u001b[39;00mvar\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtdict[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mstart_date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.nc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     tracks_nc_file \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(tracks_nc_file)[var]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tdict' is not defined"
     ]
    }
   ],
   "source": [
    "# variables to be plotted\n",
    "\n",
    "for var in tdict['varlist']: \n",
    "\n",
    "    tracks_nc_file = os.path.join(tdict['paths']['fulldir'], f\"tempest_tracks_{var}_{tdict['time']['start_date']}.nc\")\n",
    "    tracks_nc_file = xr.open_dataset(tracks_nc_file)[var]\n",
    "    multi_plot(tracks_nc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop on each time stamp in dates\n",
    "for block in pd.date_range(start=tdict['time']['start_date'], end_date=tdict['time']['end_date'], freq=str(n_days_freq)+'D'):\n",
    "    dates = pd.date_range(start=block, periods=n_days_freq, freq='D')\n",
    "    track_file = os.path.join(tdict['paths']['plotting'], f'tempest_track_{block.strftime(\"%Y%m%d\")}-{dates[-1].strftime(\"%Y%m%d\")}.txt')\n",
    "    plot_trajectories(track_file, tdict['paths']['plotting'], block, dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCs",
   "language": "python",
   "name": "tcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
